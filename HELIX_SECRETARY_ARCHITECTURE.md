# ğŸ—ï¸ HELIX SECRETARY - ESTRUTURA CRIADA

## Ãrvore de Arquivos - Fase A

```
HR/
â”œâ”€â”€ apps/
â”‚   â””â”€â”€ assistant/                           â† NOVO: Django App para RAG
â”‚       â”œâ”€â”€ __init__.py                      (15 linhas) - Package init
â”‚       â”œâ”€â”€ apps.py                          (25 linhas) - AppConfig
â”‚       â”œâ”€â”€ models.py                        (270 linhas) â­ COM PGVECTOR
â”‚       â”‚   â”œâ”€â”€ Document (TenantAware)       - Docs ingested
â”‚       â”‚   â”œâ”€â”€ DocumentChunk â­             - Vector embeddings (1536 dims)
â”‚       â”‚   â”œâ”€â”€ Conversation (TenantAware)   - Chat sessions
â”‚       â”‚   â”œâ”€â”€ Message                      - Chat history
â”‚       â”‚   â””â”€â”€ HelixConfig (TenantAware)    - Config per tenant
â”‚       â”‚
â”‚       â”œâ”€â”€ admin.py                         (140 linhas) - Admin interface
â”‚       â”‚   â”œâ”€â”€ DocumentAdmin
â”‚       â”‚   â”œâ”€â”€ DocumentChunkAdmin
â”‚       â”‚   â”œâ”€â”€ ConversationAdmin
â”‚       â”‚   â”œâ”€â”€ MessageAdmin
â”‚       â”‚   â””â”€â”€ HelixConfigAdmin
â”‚       â”‚
â”‚       â”œâ”€â”€ views.py                         (150 linhas) - API stubs
â”‚       â”‚   â”œâ”€â”€ chat_interface()             - GET /chat/
â”‚       â”‚   â”œâ”€â”€ chat_window()                - GET /chat/window/
â”‚       â”‚   â”œâ”€â”€ chat_message()               - POST /api/chat/message/
â”‚       â”‚   â”œâ”€â”€ get_conversation_history()   - GET /api/chat/history/<id>/
â”‚       â”‚   â”œâ”€â”€ create_conversation()        - POST /api/chat/new/
â”‚       â”‚   â”œâ”€â”€ list_documents()             - GET /api/documents/
â”‚       â”‚   â””â”€â”€ ingest_documents()           - POST /api/documents/ingest/
â”‚       â”‚
â”‚       â”œâ”€â”€ services.py                      (340 linhas) - RAG skeleton
â”‚       â”‚   â”œâ”€â”€ DocumentIngestion            - IngestÃ£o de docs
â”‚       â”‚   â”œâ”€â”€ RAGPipeline                  - Busca de contexto
â”‚       â”‚   â””â”€â”€ HelixAssistant               - Chat interface
â”‚       â”‚
â”‚       â”œâ”€â”€ urls.py                          (20 linhas) - URL routing
â”‚       â”‚   â”œâ”€â”€ /api/chat/message/
â”‚       â”‚   â”œâ”€â”€ /api/chat/history/
â”‚       â”‚   â”œâ”€â”€ /api/chat/new/
â”‚       â”‚   â”œâ”€â”€ /api/documents/
â”‚       â”‚   â”œâ”€â”€ /api/documents/ingest/
â”‚       â”‚   â”œâ”€â”€ /chat/
â”‚       â”‚   â””â”€â”€ /chat/window/
â”‚       â”‚
â”‚       â””â”€â”€ migrations/
â”‚           â”œâ”€â”€ __init__.py
â”‚           â””â”€â”€ 0001_initial.py              (200+ linhas)
â”‚               â”œâ”€â”€ CREATE EXTENSION pgvector
â”‚               â”œâ”€â”€ CREATE TABLE document
â”‚               â”œâ”€â”€ CREATE TABLE documentchunk
â”‚               â”œâ”€â”€ CREATE TABLE conversation
â”‚               â”œâ”€â”€ CREATE TABLE message
â”‚               â”œâ”€â”€ CREATE TABLE helixconfig
â”‚               â””â”€â”€ CREATE INDEXES
â”‚
â”œâ”€â”€ config/
â”‚   â””â”€â”€ settings.py                          (MODIFICADO)
â”‚       â””â”€â”€ LOCAL_APPS += 'apps.assistant'   â† Adicionado
â”‚
â”œâ”€â”€ requirements.txt                         (MODIFICADO)
â”‚       â”œâ”€â”€ pgvector==0.2.4                  â† Novo
â”‚       â”œâ”€â”€ langchain==0.1.4                 â† Novo
â”‚       â”œâ”€â”€ langchain-openai==0.0.5          â† Novo
â”‚       â”œâ”€â”€ langchain-postgres==0.0.9        â† Novo
â”‚       â””â”€â”€ openai==1.3.8                    â† Novo
â”‚
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ manual.md                            â† Adicionado (exemplo doc para ingest)
â”‚
â””â”€â”€ Documentation/
    â”œâ”€â”€ HELIX_SECRETARY_FASE_A_SUMMARY.md         â† Novo
    â”œâ”€â”€ HELIX_SECRETARY_FASE_B_PLANNING.md        â† Novo
    â”œâ”€â”€ HELIX_SECRETARY_READY_FOR_FASE_B.md       â† Novo
    â”œâ”€â”€ HELIX_SECRETARY_STATUS.md                 â† Novo
    â””â”€â”€ HELIX_SECRETARY_FASE_A_COMPLETE.txt       â† Novo (visual)
```

---

## ğŸ“Š EstatÃ­sticas

### Arquivos Criados/Modificados

| Tipo | Qtd | Linhas | Status |
|------|-----|--------|--------|
| **App Files** | 8 | 1,160 | âœ… |
| **Migrations** | 1 | 200+ | âœ… |
| **Config** | 1 | (+1) | âœ… |
| **Dependencies** | 1 | (+5) | âœ… |
| **Documentation** | 5 | 2,000+ | âœ… |
| **TOTAL** | **17** | **~3,400** | âœ… |

### Modelos Django

| Modelo | Campos | Ãndices | Status |
|--------|--------|---------|--------|
| **Document** | 9 | 2 | âœ… |
| **DocumentChunk** | 8 | 1 | âœ… |
| **Conversation** | 6 | 1 | âœ… |
| **Message** | 7 | 2 | âœ… |
| **HelixConfig** | 7 | 1 | âœ… |

### API Endpoints

| MÃ©todo | Endpoint | Status |
|--------|----------|--------|
| **GET** | `/chat/` | Stub â³ |
| **GET** | `/chat/window/` | Stub â³ |
| **POST** | `/api/chat/message/` | Stub â³ |
| **GET** | `/api/chat/history/<id>/` | Stub â³ |
| **POST** | `/api/chat/new/` | Stub â³ |
| **GET** | `/api/documents/` | Stub â³ |
| **POST** | `/api/documents/ingest/` | Stub â³ |

---

## ğŸ”— Relacionamentos de Modelos

```
Document (1) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ (N) DocumentChunk
   â”‚                              â”‚
   â””â”€ company (FK)    â”œâ”€ embedding (1536 dims)
   â”œâ”€ title           â””â”€ document (FK)
   â”œâ”€ source_path
   â”œâ”€ content
   â””â”€ ingested_at

Company â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€ Document
            â”‚
            â”œâ”€â”€â”€â”€â”€â”€â”€â”€ Conversation
            â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€ HelixConfig

Conversation (1) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ (N) Message
   â”‚                                â”‚
   â”œâ”€ user (FK)           â””â”€ role (user|assistant|system)
   â”œâ”€ company (FK)        â”œâ”€ content
   â””â”€ title               â””â”€ context_sources (JSON)

User â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ (N) Conversation
```

---

## ğŸ¯ RAG Classes (services.py)

```python
DocumentIngestion
â”œâ”€â”€ discover_documents()      # Encontrar arquivos
â”œâ”€â”€ parse_document()          # Ler e detectar tipo
â”œâ”€â”€ chunk_text()              # Dividir em chunks
â”œâ”€â”€ generate_embeddings()     # OpenAI embeddings (ASYNC)
â””â”€â”€ ingest_documents()        # Pipeline completo

RAGPipeline
â”œâ”€â”€ retrieve_context()        # pgvector similarity search
â”œâ”€â”€ build_prompt()            # Formatar prompt com contexto
â””â”€â”€ answer_query()            # Query â†’ Response (ASYNC)

HelixAssistant
â”œâ”€â”€ get_config()              # Get tenant config
â”œâ”€â”€ chat()                    # Full conversation flow (ASYNC)
â””â”€â”€ summarize_conversation()  # Auto-title generator
```

---

## ğŸ”§ Configuration Flow

```
Environment Variables (.env)
    â”‚
    â”œâ”€ OPENAI_API_KEY
    â”œâ”€ OPENAI_MODEL (gpt-3.5-turbo)
    â”œâ”€ EMBEDDING_MODEL (text-embedding-3-small)
    â”‚
    â†“
settings.py (Django)
    â”‚
    â”œâ”€ INSTALLED_APPS += 'apps.assistant'
    â”œâ”€ RAG_CONFIG = {...}
    â”‚
    â†“
services.py (RAG Logic)
    â”‚
    â”œâ”€ OpenAIEmbeddings(api_key, model)
    â”œâ”€ ChatOpenAI(api_key, model, temperature)
    â”‚
    â†“
Models (Database)
    â”‚
    â”œâ”€ Document â†’ DocumentChunk (pgvector)
    â””â”€ Conversation â†’ Message
```

---

## ğŸ“ˆ Data Flow (Fase B+)

```
User Message
    â”‚
    â†“
views.chat_message()
    â”‚
    â”œâ”€â†’ HelixAssistant.chat()
    â”‚   â”‚
    â”‚   â”œâ”€â†’ RAGPipeline.retrieve_context(query)
    â”‚   â”‚   â”‚
    â”‚   â”‚   â”œâ”€ OpenAI.embed_query(query) â†’ embedding vector
    â”‚   â”‚   â”‚
    â”‚   â”‚   â”œâ”€ pgvector similarity search
    â”‚   â”‚   â”‚   SELECT * FROM documentchunk
    â”‚   â”‚   â”‚   ORDER BY embedding <-> query_embedding
    â”‚   â”‚   â”‚   LIMIT k
    â”‚   â”‚   â”‚
    â”‚   â”‚   â””â”€ Return top-K DocumentChunks
    â”‚   â”‚
    â”‚   â”œâ”€â†’ RAGPipeline.build_prompt(query, context)
    â”‚   â”‚   â””â”€ Format: SystemPrompt + Context + Query
    â”‚   â”‚
    â”‚   â”œâ”€â†’ ChatOpenAI.astream(prompt) â†’ Response (streaming)
    â”‚   â”‚
    â”‚   â””â”€â†’ Create Message record
    â”‚       â”œâ”€ role='assistant'
    â”‚       â”œâ”€ content=response
    â”‚       â””â”€ context_sources=[...]
    â”‚
    â””â”€â†’ Return response to client (HTMX)
```

---

## ğŸ—„ï¸ Database Schema (pgvector)

```sql
-- Document Table
CREATE TABLE assistant_document (
    id BIGSERIAL PRIMARY KEY,
    title VARCHAR(255) NOT NULL,
    source_path VARCHAR(500) NOT NULL,
    content TEXT NOT NULL,
    content_type VARCHAR(50),
    version VARCHAR(20) DEFAULT '1.0',
    is_active BOOLEAN DEFAULT TRUE,
    ingested_at TIMESTAMP AUTO_NOW_ADD,
    updated_at TIMESTAMP AUTO_NOW,
    company_id BIGINT REFERENCES core_company,
    -- INDEX: (company_id, is_active), (source_path)
);

-- DocumentChunk Table (com pgvector!)
CREATE TABLE assistant_documentchunk (
    id BIGSERIAL PRIMARY KEY,
    document_id BIGINT REFERENCES assistant_document ON DELETE CASCADE,
    chunk_index INTEGER NOT NULL,
    content TEXT NOT NULL,
    embedding vector(1536),              -- â† PGVECTOR FIELD!
    token_count INTEGER DEFAULT 0,
    embedding_model VARCHAR(100),
    created_at TIMESTAMP AUTO_NOW_ADD,
    updated_at TIMESTAMP AUTO_NOW,
    -- UNIQUE: (document_id, chunk_index)
    -- INDEX: (document_id, chunk_index)
);

-- Conversation Table
CREATE TABLE assistant_conversation (
    id BIGSERIAL PRIMARY KEY,
    user_id BIGINT REFERENCES auth_user,
    company_id BIGINT REFERENCES core_company,
    title VARCHAR(255),
    is_active BOOLEAN DEFAULT TRUE,
    created_at TIMESTAMP AUTO_NOW_ADD,
    updated_at TIMESTAMP AUTO_NOW,
    -- INDEX: (user_id, company_id, -created_at)
);

-- Message Table
CREATE TABLE assistant_message (
    id BIGSERIAL PRIMARY KEY,
    conversation_id BIGINT REFERENCES assistant_conversation ON DELETE CASCADE,
    role VARCHAR(20) NOT NULL,  -- user|assistant|system
    content TEXT NOT NULL,
    context_sources JSONB DEFAULT '[]',
    tokens_used INTEGER DEFAULT 0,
    created_at TIMESTAMP AUTO_NOW_ADD,
    updated_at TIMESTAMP AUTO_NOW,
    -- INDEX: (conversation_id, created_at), (role)
);

-- HelixConfig Table
CREATE TABLE assistant_helixconfig (
    id BIGSERIAL PRIMARY KEY,
    company_id BIGINT REFERENCES core_company UNIQUE,
    is_enabled BOOLEAN DEFAULT TRUE,
    system_prompt TEXT,
    max_context_chunks INTEGER DEFAULT 5,
    temperature FLOAT DEFAULT 0.3,
    enable_citation BOOLEAN DEFAULT TRUE,
    similarity_threshold FLOAT DEFAULT 0.7,
    created_at TIMESTAMP AUTO_NOW_ADD,
    updated_at TIMESTAMP AUTO_NOW,
);

-- Enable pgvector extension
CREATE EXTENSION IF NOT EXISTS vector;
```

---

## ğŸ”„ Admin Interface

```
Django Admin
â”‚
â”œâ”€â”€ Assistant
â”‚   â”œâ”€â”€ Documents
â”‚   â”‚   â”œâ”€â”€ List View: [title | source_path | company | is_active | ingested_at]
â”‚   â”‚   â”œâ”€â”€ Search: title, source_path, content
â”‚   â”‚   â”œâ”€â”€ Filter: company, is_active, content_type
â”‚   â”‚   â””â”€â”€ Fieldsets: Info, Content, Metadata, Audit
â”‚   â”‚
â”‚   â”œâ”€â”€ Document Chunks
â”‚   â”‚   â”œâ”€â”€ List View: [document | chunk_index | token_count | embedding_model | created_at]
â”‚   â”‚   â”œâ”€â”€ Search: document__title, content
â”‚   â”‚   â”œâ”€â”€ Filter: document__company, embedding_model
â”‚   â”‚   â””â”€â”€ Readonly: created_at, updated_at
â”‚   â”‚
â”‚   â”œâ”€â”€ Conversations
â”‚   â”‚   â”œâ”€â”€ List View: [user | title | company | is_active | created_at | message_count]
â”‚   â”‚   â”œâ”€â”€ Search: user__username, title
â”‚   â”‚   â”œâ”€â”€ Filter: company, is_active
â”‚   â”‚   â””â”€â”€ Custom: message_count() method
â”‚   â”‚
â”‚   â”œâ”€â”€ Messages
â”‚   â”‚   â”œâ”€â”€ List View: [conversation | role | content_preview | tokens_used | created_at]
â”‚   â”‚   â”œâ”€â”€ Search: conversation__user__username, content
â”‚   â”‚   â”œâ”€â”€ Filter: conversation__company, role
â”‚   â”‚   â””â”€â”€ Custom: content_preview() truncated to 100 chars
â”‚   â”‚
â”‚   â””â”€â”€ Helix Configuration
â”‚       â”œâ”€â”€ List View: [company | is_enabled | temperature | max_context_chunks]
â”‚       â”œâ”€â”€ Filter: company, is_enabled
â”‚       â”œâ”€â”€ Fieldsets: Config, System Prompt, Response Settings, Features
â”‚       â””â”€â”€ Readonly: created_at, updated_at
```

---

## ğŸ“ URL Routing

```
URLs: apps/assistant/urls.py (app_name='assistant')

GET  /chat/                              â†’ chat_interface()
GET  /chat/window/                       â†’ chat_window()
POST /api/chat/message/                  â†’ chat_message()
GET  /api/chat/history/<int:id>/         â†’ get_conversation_history()
POST /api/chat/new/                      â†’ create_conversation()
GET  /api/documents/                     â†’ list_documents()
POST /api/documents/ingest/              â†’ ingest_documents()

(NÃ£o integrado em config/urls.py - fazer em Fase C)
```

---

## ğŸ¨ Onyx Color Palette (Fase C)

```css
--color-primary:    #00080D  /* Black */
--color-secondary:  #274B59  /* Teal */
--color-tertiary:   #122E40  /* Navy */
--color-text:       #D0E5F2  /* Light Blue */

Helix Chat Colors:
--user-message:     bg-blue-600 text-white
--assistant:        bg-teal-100 text-gray-900
--citation:         text-blue-600 underline
```

---

**âœ… Fase A Architecture Complete**  
**ğŸš€ Ready for Fase B Implementation**

PrÃ³ximo: Implementar RAG services em `apps/assistant/services.py`
