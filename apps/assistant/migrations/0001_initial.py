# Generated by Django 5.1.3 on 2025-12-02 19:13

import django.contrib.postgres.fields
import uuid
from django.db import migrations, models


class Migration(migrations.Migration):

    initial = True

    dependencies = [
    ]

    operations = [
        migrations.CreateModel(
            name='Conversation',
            fields=[
                ('id', models.BigAutoField(primary_key=True, serialize=False)),
                ('uuid', models.UUIDField(default=uuid.uuid4, editable=False, unique=True)),
                ('created_at', models.DateTimeField(auto_now_add=True, db_index=True)),
                ('updated_at', models.DateTimeField(auto_now=True)),
                ('created_by', models.CharField(blank=True, max_length=255, null=True)),
                ('updated_by', models.CharField(blank=True, max_length=255, null=True)),
                ('title', models.CharField(blank=True, help_text='Auto-generated conversation title', max_length=255)),
                ('is_active', models.BooleanField(default=True, help_text='Mark as archived')),
            ],
            options={
                'verbose_name': 'Conversation',
                'verbose_name_plural': 'Conversations',
                'ordering': ['-created_at'],
            },
        ),
        migrations.CreateModel(
            name='Document',
            fields=[
                ('id', models.BigAutoField(primary_key=True, serialize=False)),
                ('uuid', models.UUIDField(default=uuid.uuid4, editable=False, unique=True)),
                ('created_at', models.DateTimeField(auto_now_add=True, db_index=True)),
                ('created_by', models.CharField(blank=True, max_length=255, null=True)),
                ('updated_by', models.CharField(blank=True, max_length=255, null=True)),
                ('title', models.CharField(help_text="Document title (e.g., 'Installation Guide')", max_length=255)),
                ('source_path', models.CharField(help_text="Original file path (e.g., 'docs/setup.md')", max_length=500)),
                ('content', models.TextField(help_text='Full document content')),
                ('content_type', models.CharField(choices=[('markdown', 'Markdown'), ('text', 'Plain Text'), ('html', 'HTML')], default='markdown', max_length=50)),
                ('version', models.CharField(default='1.0', help_text='Document version', max_length=20)),
                ('is_active', models.BooleanField(default=True, help_text='Include in RAG knowledge base')),
                ('ingested_at', models.DateTimeField(auto_now_add=True)),
                ('updated_at', models.DateTimeField(auto_now=True)),
            ],
            options={
                'verbose_name': 'Document',
                'verbose_name_plural': 'Documents',
                'ordering': ['-ingested_at'],
            },
        ),
        migrations.CreateModel(
            name='DocumentChunk',
            fields=[
                ('id', models.BigAutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('chunk_index', models.IntegerField(help_text='Sequential chunk number within document')),
                ('content', models.TextField(help_text='Text content of this chunk')),
                ('embedding', django.contrib.postgres.fields.ArrayField(base_field=models.FloatField(), blank=True, help_text='OpenAI embedding vector (1536 dimensions for text-embedding-3-small)', null=True, size=1536)),
                ('token_count', models.IntegerField(default=0, help_text='Token count for this chunk')),
                ('embedding_model', models.CharField(default='text-embedding-3-small', help_text='OpenAI model used for embedding', max_length=100)),
                ('created_at', models.DateTimeField(auto_now_add=True)),
                ('updated_at', models.DateTimeField(auto_now=True)),
            ],
            options={
                'verbose_name': 'Document Chunk',
                'verbose_name_plural': 'Document Chunks',
                'ordering': ['document', 'chunk_index'],
            },
        ),
        migrations.CreateModel(
            name='HelixConfig',
            fields=[
                ('id', models.BigAutoField(primary_key=True, serialize=False)),
                ('uuid', models.UUIDField(default=uuid.uuid4, editable=False, unique=True)),
                ('created_at', models.DateTimeField(auto_now_add=True, db_index=True)),
                ('updated_at', models.DateTimeField(auto_now=True)),
                ('is_active', models.BooleanField(db_index=True, default=True)),
                ('created_by', models.CharField(blank=True, max_length=255, null=True)),
                ('updated_by', models.CharField(blank=True, max_length=255, null=True)),
                ('is_enabled', models.BooleanField(default=True, help_text='Enable Helix for this company')),
                ('system_prompt', models.TextField(default='Você é o Secretário Virtual do sistema Onyx Helix. Responda de forma concisa, profissional e sempre baseando-se estritamente no contexto fornecido. Se não souber a resposta, diga que precisa de ajuda de um humano.', help_text='System prompt for LLM (Portuguese)')),
                ('max_context_chunks', models.IntegerField(default=5, help_text='Maximum number of document chunks to use as context')),
                ('temperature', models.FloatField(default=0.3, help_text='LLM temperature (0.0 to 1.0)')),
                ('enable_citation', models.BooleanField(default=True, help_text='Include source citations in responses')),
                ('similarity_threshold', models.FloatField(default=0.7, help_text='Minimum similarity score for relevant chunks (0.0 to 1.0)')),
            ],
            options={
                'verbose_name': 'Helix Configuration',
                'verbose_name_plural': 'Helix Configurations',
            },
        ),
        migrations.CreateModel(
            name='Message',
            fields=[
                ('id', models.BigAutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('role', models.CharField(choices=[('user', 'User'), ('assistant', 'Assistant (Helix)'), ('system', 'System')], help_text='Who sent the message', max_length=20)),
                ('content', models.TextField(help_text='Message content')),
                ('context_sources', models.JSONField(blank=True, default=list, help_text='Documents/chunks used for response (RAG context)')),
                ('tokens_used', models.IntegerField(default=0, help_text='OpenAI tokens consumed by this message')),
                ('created_at', models.DateTimeField(auto_now_add=True)),
                ('updated_at', models.DateTimeField(auto_now=True)),
            ],
            options={
                'verbose_name': 'Message',
                'verbose_name_plural': 'Messages',
                'ordering': ['created_at'],
            },
        ),
    ]
